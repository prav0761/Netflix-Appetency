{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa54f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81c6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type        to reduce memory usage.            \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                #    df[col] = df[col].astype(np.float16)\n",
    "                #elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                #    df[col] = df[col].astype(np.float32)\n",
    "                #else:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de026fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")\n",
    "target=df['target']\n",
    "df1=df.drop('target',axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bda882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Columns: 508 entries, id to feature_506\n",
      "dtypes: float64(143), int64(273), object(92)\n",
      "memory usage: 271.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv(\"test.csv\")\n",
    "print(df1.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb90c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape (70000, 508)\n",
      "test_shape (30000, 508)\n"
     ]
    }
   ],
   "source": [
    "print('train_shape',df1.shape)\n",
    "print('test_shape',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6943c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING THE OBJECT AND INT COLUMNS\n",
    "object_columns_train=df1.select_dtypes(include='object')\n",
    "object_columns_test=df_test.select_dtypes(include='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c911b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_train=df1.drop(object_columns_train,axis='columns')\n",
    "df2_test=df_test.drop(object_columns_test,axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3766a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING COLUMNS WHICH HAS MORE THAN 50% NAN VALUES\n",
    "def removemorethan50pernavalues(dataframe):\n",
    "    for col in dataframe.columns:\n",
    "        if (dataframe[col].isna().sum()/dataframe.shape[0]>0.50):\n",
    "            dataframe.drop(col,axis='columns',inplace=True)\n",
    "df3_train=df2_train.copy()\n",
    "df3_test=df2_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7faf7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 396)\n",
      "(30000, 396)\n"
     ]
    }
   ],
   "source": [
    "removemorethan50pernavalues(df3_train)\n",
    "removemorethan50pernavalues(df3_test)\n",
    "df4_train=df3_train.copy()\n",
    "df4_test=df3_test.copy()\n",
    "print(df4_train.shape)\n",
    "print(df4_test.shape)\n",
    "## REMOVING ZERO VARIANCE COLUMNS\n",
    "zero_var=[]\n",
    "for col in df4_train.columns:\n",
    "        if (len(df4_train[col].unique()))==1:\n",
    "            zero_var.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "479993c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df44_train=df4_train.drop(zero_var,axis='columns')\n",
    "df44_test=df4_test.drop(zero_var,axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4834ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def removezerovariancecolumns(dataframe):\n",
    "    #for col in dataframe.columns:\n",
    "        #if (len(dataframe[col].unique()))==1:\n",
    "            #dataframe.drop(col,axis='columns',inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a194d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removezerovariancecolumns(df4_train)\n",
    "#removezerovariancecolumns(df4_test)\n",
    "df5_train=df44_train.copy()\n",
    "df5_test=df44_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723ca5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nan values with mode for col with unique values less than 3\n",
    "for col in df5_train.columns:\n",
    "    if (len(df5_train[col].unique()))<3:\n",
    "        df5_train[col].fillna(df5_train[col].mode(),inplace=True)\n",
    "for col in df5_test.columns:\n",
    "    if (len(df5_test[col].unique()))<3:\n",
    "        df5_test[col].fillna(df5_test[col].mode(),inplace=True)\n",
    "df6_train=df5_train.copy()\n",
    "df6_test=df5_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a093b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_490</th>\n",
       "      <th>feature_492</th>\n",
       "      <th>feature_494</th>\n",
       "      <th>feature_496</th>\n",
       "      <th>feature_497</th>\n",
       "      <th>feature_499</th>\n",
       "      <th>feature_501</th>\n",
       "      <th>feature_503</th>\n",
       "      <th>feature_504</th>\n",
       "      <th>feature_506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1.758</td>\n",
       "      <td>15.018333</td>\n",
       "      <td>3549</td>\n",
       "      <td>22515</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-22.837156</td>\n",
       "      <td>-13.821311</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>147.361188</td>\n",
       "      <td>47.191772</td>\n",
       "      <td>10.499621</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.087787</td>\n",
       "      <td>140.228572</td>\n",
       "      <td>1.122803</td>\n",
       "      <td>295.047825</td>\n",
       "      <td>-20.201758</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8841</td>\n",
       "      <td>28896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.582679</td>\n",
       "      <td>150.159626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-34.420654</td>\n",
       "      <td>242.227486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>99981</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8351</td>\n",
       "      <td>91413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.998692</td>\n",
       "      <td>37.908906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>99982</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271</td>\n",
       "      <td>390</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-30.700138</td>\n",
       "      <td>-20.344487</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>99992</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>5655</td>\n",
       "      <td>51403</td>\n",
       "      <td>-96.920542</td>\n",
       "      <td>138.281865</td>\n",
       "      <td>793.082314</td>\n",
       "      <td>267.236353</td>\n",
       "      <td>-72.497909</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>99993</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.716540</td>\n",
       "      <td>-28.212716</td>\n",
       "      <td>0.217039</td>\n",
       "      <td>-0.039371</td>\n",
       "      <td>-21.546634</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>99995</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>47020</td>\n",
       "      <td>154642</td>\n",
       "      <td>-21.029068</td>\n",
       "      <td>-8.730485</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.029792</td>\n",
       "      <td>-21.026001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  feature_14  feature_15  feature_25  feature_26  feature_35  \\\n",
       "0          5       1.758   15.018333        3549       22515 -100.000000   \n",
       "1          7       0.000    0.000000           0           0 -100.000000   \n",
       "2          9       0.000    0.000000           0           0  -21.087787   \n",
       "3         11       0.000    0.000000        8841       28896    0.000000   \n",
       "4         14       0.000    0.000000           0           0    0.000000   \n",
       "...      ...         ...         ...         ...         ...         ...   \n",
       "29995  99981       0.000    0.000000        8351       91413    0.000000   \n",
       "29996  99982       0.000    0.000000         271         390  100.000000   \n",
       "29997  99992       0.000    0.249000        5655       51403  -96.920542   \n",
       "29998  99993       0.000    0.000000           0           0  -21.716540   \n",
       "29999  99995       0.000    0.733333       47020      154642  -21.029068   \n",
       "\n",
       "       feature_36  feature_37  feature_38  feature_39  ...  feature_490  \\\n",
       "0      100.000000  -22.837156  -13.821311 -100.000000  ...            0   \n",
       "1      147.361188   47.191772   10.499621 -100.000000  ...            0   \n",
       "2      140.228572    1.122803  295.047825  -20.201758  ...            0   \n",
       "3        0.000000   18.582679  150.159626    0.000000  ...            0   \n",
       "4     -100.000000  -34.420654  242.227486    0.000000  ...            0   \n",
       "...           ...         ...         ...         ...  ...          ...   \n",
       "29995    0.000000   -2.998692   37.908906    0.000000  ...            0   \n",
       "29996  100.000000  -30.700138  -20.344487  100.000000  ...            0   \n",
       "29997  138.281865  793.082314  267.236353  -72.497909  ...            0   \n",
       "29998  -28.212716    0.217039   -0.039371  -21.546634  ...            0   \n",
       "29999   -8.730485    0.003883    0.029792  -21.026001  ...            0   \n",
       "\n",
       "       feature_492  feature_494  feature_496  feature_497  feature_499  \\\n",
       "0                0            0            0            0            0   \n",
       "1                0            0            0            0            0   \n",
       "2                0            0            0            0            0   \n",
       "3                0            0            0            0            0   \n",
       "4                0            0            0            0            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29995            0            0            0            0            0   \n",
       "29996            0            0            0            0            0   \n",
       "29997            0            0            0            0            0   \n",
       "29998            0            0            0            0            0   \n",
       "29999            0            0            0            0            0   \n",
       "\n",
       "       feature_501  feature_503  feature_504  feature_506  \n",
       "0                0            0            0            0  \n",
       "1                0            0            0            0  \n",
       "2                0            0            0            0  \n",
       "3                0            0            0            0  \n",
       "4                0            0            0            0  \n",
       "...            ...          ...          ...          ...  \n",
       "29995            0            0            0            0  \n",
       "29996            0            0            0            0  \n",
       "29997            0            0            0            0  \n",
       "29998            0            0            0            0  \n",
       "29999            0            0            0            0  \n",
       "\n",
       "[30000 rows x 343 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing nan values with median for col with unique values more than 4\n",
    "for col in df6_train.columns:\n",
    "    if(len(df6_train[col].unique()))>3:\n",
    "        df6_train[col].fillna(df6_train[col].median(),inplace=True)\n",
    "for col in df6_test.columns:\n",
    "    if(len(df6_test[col].unique()))>3:\n",
    "        df6_test[col].fillna(df6_test[col].median(),inplace=True)\n",
    "df7_train=df6_train.copy()\n",
    "df7_test=df6_test.copy()\n",
    "ID_train=df7_train['id']\n",
    "ID_test=df7_test['id']\n",
    "df77_train=df7_train.drop('id',axis='columns')\n",
    "df77_test=df7_test.drop('id',axis='columns')\n",
    "\n",
    "df7_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b594265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df10_train=pd.DataFrame(df9_train)\n",
    "#df10_test=pd.DataFrame(df9_test)\n",
    "df10_train=df77_train.copy()\n",
    "df10_test=df77_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5931fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING OBJECT COLUMNS WITH MORE THAN 50% NAN VALUES\n",
    "removemorethan50pernavalues(object_columns_train)\n",
    "removemorethan50pernavalues(object_columns_test)\n",
    "ob_train=object_columns_train.copy()\n",
    "ob_test=object_columns_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a3db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING DATETIME FEATURES\n",
    "datetime_features = [\"feature_191\", \"feature_192\",\"feature_199\", \"feature_201\"]\n",
    "def convertingdatetime(dataframe):\n",
    "    for i in datetime_features:\n",
    "        dataframe[i]=pd.to_datetime(dataframe[i])\n",
    "convertingdatetime(ob_train)\n",
    "convertingdatetime(ob_test)\n",
    "ob1_train=ob_train.copy()\n",
    "ob1_test=ob_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a72879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertingtoymd(dataframe):\n",
    "    for col in dataframe:\n",
    "        if dataframe[col].dtype=='<M8[ns]':\n",
    "            dataframe[f\"{col}year\"] = pd.to_datetime(dataframe[col]).dt.year\n",
    "            dataframe[f\"{col}month\"] = pd.to_datetime(dataframe[col]).dt.month\n",
    "            dataframe[f\"{col}day\"] = pd.to_datetime(dataframe[col]).dt.day\n",
    "convertingtoymd(ob1_train)\n",
    "convertingtoymd(ob1_test)\n",
    "\n",
    "ob2_train=ob1_train.copy()\n",
    "ob2_test=ob1_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1aa0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropdatetime(dataframe):\n",
    "    for i in dataframe:\n",
    "        if dataframe[i].dtype=='<M8[ns]':\n",
    "            dataframe.drop(i,axis='columns',inplace=True)\n",
    "dropdatetime(ob2_train)\n",
    "dropdatetime(ob2_test)\n",
    "ob3_train=ob2_train.copy()\n",
    "ob3_test=ob2_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27dc1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removng cols with more classes\n",
    "def removecolwithmoreclasses(dataframe):\n",
    "    for col in dataframe:\n",
    "        if dataframe[col].dtype=='object':\n",
    "            if (len(dataframe[col].unique()))>100:\n",
    "                dataframe.drop(col,axis='columns',inplace=True)\n",
    "removecolwithmoreclasses(ob3_train)\n",
    "removecolwithmoreclasses(ob3_test)\n",
    "ob4_train=ob3_train.copy()\n",
    "ob4_test=ob3_test.copy()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8cc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_var_obj=[]\n",
    "for col in ob4_train.columns:\n",
    "        if (len(ob4_train[col].unique()))==1:\n",
    "            zero_var_obj.append(col)\n",
    "zero_var_obj\n",
    "ob44_train=ob4_train.drop(zero_var_obj,axis='columns')\n",
    "ob44_test=ob4_test.drop(zero_var_obj,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0a556fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_191day</th>\n",
       "      <th>feature_192year</th>\n",
       "      <th>feature_192month</th>\n",
       "      <th>feature_192day</th>\n",
       "      <th>feature_199year</th>\n",
       "      <th>feature_199month</th>\n",
       "      <th>feature_199day</th>\n",
       "      <th>feature_201year</th>\n",
       "      <th>feature_201month</th>\n",
       "      <th>feature_201day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C1</td>\n",
       "      <td>C5</td>\n",
       "      <td>C11</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C19</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "      <td>C1</td>\n",
       "      <td>C2</td>\n",
       "      <td>C0</td>\n",
       "      <td>C23</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C3</td>\n",
       "      <td>C5</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "      <td>C0</td>\n",
       "      <td>C22</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C1</td>\n",
       "      <td>C5</td>\n",
       "      <td>C1</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C2</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C3</td>\n",
       "      <td>C3</td>\n",
       "      <td>C11</td>\n",
       "      <td>C2</td>\n",
       "      <td>C0</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C3</td>\n",
       "      <td>C1</td>\n",
       "      <td>C11</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C14</td>\n",
       "      <td>C1</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C5</td>\n",
       "      <td>C5</td>\n",
       "      <td>C2</td>\n",
       "      <td>C2</td>\n",
       "      <td>C0</td>\n",
       "      <td>C17</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>C11</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C5</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C1</td>\n",
       "      <td>C5</td>\n",
       "      <td>C1</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "      <td>C8</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C2</td>\n",
       "      <td>C5</td>\n",
       "      <td>C2</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>C20</td>\n",
       "      <td>C0</td>\n",
       "      <td>C0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0 feature_1 feature_2 feature_3 feature_4 feature_16 feature_23  \\\n",
       "0            C0        C0        C1        C5       C11         C0         C0   \n",
       "1            C0        C0        C3        C5        C1         C2         C0   \n",
       "2            C0        C0        C3        C5        C2         C1         C0   \n",
       "3            C0        C0        C1        C5        C1         C0         C0   \n",
       "4            C0        C0        C3        C3       C11         C2         C0   \n",
       "...         ...       ...       ...       ...       ...        ...        ...   \n",
       "69995        C0        C0        C3        C1       C11         C0         C0   \n",
       "69996        C0        C0        C5        C5        C2         C2         C0   \n",
       "69997        C0        C0        C3        C2       C11         C0         C0   \n",
       "69998        C0        C0        C1        C5        C1         C2         C1   \n",
       "69999        C0        C0        C2        C5        C2         C0         C0   \n",
       "\n",
       "      feature_24 feature_27 feature_28  ... feature_191day feature_192year  \\\n",
       "0            C19         C0         C0  ...           10.0          2017.0   \n",
       "1            C23         C0         C0  ...           25.0          2015.0   \n",
       "2            C22         C0         C0  ...           27.0          2015.0   \n",
       "3             C2         C0         C0  ...            2.0          2014.0   \n",
       "4             C3         C1         C1  ...           20.0          2013.0   \n",
       "...          ...        ...        ...  ...            ...             ...   \n",
       "69995        C14         C1         C0  ...           27.0          2014.0   \n",
       "69996        C17         C0         C0  ...           19.0          2016.0   \n",
       "69997         C5         C1         C1  ...           14.0          2015.0   \n",
       "69998         C8         C0         C0  ...           29.0          2017.0   \n",
       "69999        C20         C0         C0  ...           23.0          2018.0   \n",
       "\n",
       "      feature_192month feature_192day feature_199year feature_199month  \\\n",
       "0                 11.0           10.0            2017               11   \n",
       "1                  3.0           25.0            2017                2   \n",
       "2                  1.0           27.0            2016                3   \n",
       "3                  1.0            4.0            2014                1   \n",
       "4                 10.0            9.0            2013               10   \n",
       "...                ...            ...             ...              ...   \n",
       "69995              1.0            2.0            2014                1   \n",
       "69996              9.0           19.0            2016                9   \n",
       "69997              7.0           25.0            2015                7   \n",
       "69998             11.0           29.0            2017               11   \n",
       "69999              1.0           23.0            2018                1   \n",
       "\n",
       "      feature_199day feature_201year feature_201month feature_201day  \n",
       "0                 10          2017.0             11.0           10.0  \n",
       "1                  4          2015.0              3.0           25.0  \n",
       "2                 24          2015.0              1.0           27.0  \n",
       "3                  4          2014.0              1.0            4.0  \n",
       "4                  9          2013.0             10.0            9.0  \n",
       "...              ...             ...              ...            ...  \n",
       "69995              2          2014.0              1.0            2.0  \n",
       "69996             19          2016.0              9.0           19.0  \n",
       "69997             25          2015.0              7.0           25.0  \n",
       "69998             29          2017.0             11.0           29.0  \n",
       "69999             23          2018.0              1.0           23.0  \n",
       "\n",
       "[70000 rows x 74 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob5_train=ob44_train.copy()\n",
    "ob5_test=ob44_test.copy()\n",
    "ob5_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09331221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACING THE NAN VALUES FOR OBJECT COLUMNS WITH MODE\n",
    "for i in ob5_train:\n",
    "    ob5_train[i].fillna(ob5_train[i].mode()[0],inplace=True)\n",
    "for i in ob5_test:\n",
    "    ob5_test[i].fillna(ob5_test[i].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "484f32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob6_train=ob5_train.copy()\n",
    "ob6_test=ob5_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c883a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 342)\n",
      "(30000, 342)\n",
      "(70000, 74)\n",
      "(30000, 74)\n"
     ]
    }
   ],
   "source": [
    "print(df10_train.shape)\n",
    "print(df10_test.shape)\n",
    "print(ob6_train.shape)\n",
    "print(ob6_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85b2a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATING THE OBJECT AND INT COLUMNS\n",
    "frames1=[ob6_train,df10_train]\n",
    "frames2=[ob6_test,df10_test]\n",
    "\n",
    "final_train=pd.concat(frames1,axis=1)\n",
    "final_test=pd.concat(frames2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3bba1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING THE OBJECT COLUMNS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "def labelencoding(dataframe):\n",
    "    for i in dataframe:\n",
    "        if dataframe[i].dtype=='object':\n",
    "            dataframe[i]=labelencoder.fit_transform(dataframe[i])\n",
    "labelencoding(final_train)\n",
    "labelencoding(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b03ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final1_train=final_train.copy()\n",
    "final1_test=final_test.copy()\n",
    "X_train=final1_train.copy()\n",
    "X_test=final1_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dcb07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27ed8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 416)\n",
      "(30000, 416)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93d688f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_307        0.335261\n",
       "feature_297        0.166057\n",
       "feature_191year    0.156897\n",
       "feature_199year    0.154425\n",
       "feature_192year    0.146387\n",
       "                     ...   \n",
       "feature_82        -0.113800\n",
       "feature_29        -0.114935\n",
       "feature_110       -0.121336\n",
       "feature_108       -0.122240\n",
       "feature_81        -0.157007\n",
       "Length: 416, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=X_train.corrwith(y_train)\n",
    "corr.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93e859fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING XGB BOOST\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f171fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 416)\n",
      "(14000, 416)\n",
      "(56000,)\n",
      "(14000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train1,X_test1,y_train1,y_test1= train_test_split(X_train,y_train,test_size=0.2)\n",
    "print(X_train1.shape)\n",
    "print(X_test1.shape)\n",
    "print(y_train1.shape)\n",
    "print(y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ee37afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING THE DATE TO XGBOOST ORIGINAL API FOR MODEL TUNING\n",
    "dtrain = xgb.DMatrix(X_train1, label=y_train1)\n",
    "dtest = xgb.DMatrix(X_test1, label=y_test1)\n",
    "drealtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "drealtest = xgb.DMatrix(X_test)\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc943ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTIALIZING THE PARAMETERS\n",
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'auc'\n",
    "}\n",
    "NUM_BOOST_ROUNDS=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3208bd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-auc:0.75660\n",
      "[1]\tTest-auc:0.76463\n",
      "[2]\tTest-auc:0.76776\n",
      "[3]\tTest-auc:0.77015\n",
      "[4]\tTest-auc:0.77175\n",
      "[5]\tTest-auc:0.77287\n",
      "[6]\tTest-auc:0.77442\n",
      "[7]\tTest-auc:0.77616\n",
      "[8]\tTest-auc:0.77717\n",
      "[9]\tTest-auc:0.77842\n",
      "[10]\tTest-auc:0.77843\n",
      "[11]\tTest-auc:0.77973\n",
      "[12]\tTest-auc:0.78036\n",
      "[13]\tTest-auc:0.78110\n",
      "[14]\tTest-auc:0.78107\n",
      "[15]\tTest-auc:0.78107\n",
      "[16]\tTest-auc:0.78122\n",
      "[17]\tTest-auc:0.78200\n",
      "[18]\tTest-auc:0.78290\n",
      "[19]\tTest-auc:0.78285\n",
      "[20]\tTest-auc:0.78280\n",
      "[21]\tTest-auc:0.78255\n",
      "[22]\tTest-auc:0.78281\n",
      "[23]\tTest-auc:0.78255\n",
      "[24]\tTest-auc:0.78235\n",
      "[25]\tTest-auc:0.78159\n",
      "[26]\tTest-auc:0.78132\n",
      "[27]\tTest-auc:0.78118\n",
      "[28]\tTest-auc:0.78126\n",
      "Best AUC: 0.78, found at round 18\n"
     ]
    }
   ],
   "source": [
    "# FINDING THE BASELINE AUC SCORE\n",
    "xbg_model1 = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=NUM_BOOST_ROUNDS,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "print(\"Best AUC: {:.2f}, found at round {}\".format(\n",
    "                 xbg_model1.best_score,\n",
    "                 xbg_model1.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79113c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.764386</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.751829</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.773539</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.758724</td>\n",
       "      <td>0.003432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778306</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.761771</td>\n",
       "      <td>0.003216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782969</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.763698</td>\n",
       "      <td>0.003182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786983</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.765753</td>\n",
       "      <td>0.003163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.790747</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.767345</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.794328</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.769108</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.770263</td>\n",
       "      <td>0.003781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.802219</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.003715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.806012</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.772297</td>\n",
       "      <td>0.003747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.809383</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.773047</td>\n",
       "      <td>0.003529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.812279</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.773838</td>\n",
       "      <td>0.003295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.815321</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.774247</td>\n",
       "      <td>0.003304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.817655</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.774688</td>\n",
       "      <td>0.003512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.820461</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.774701</td>\n",
       "      <td>0.003553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.822673</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.774599</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.774804</td>\n",
       "      <td>0.003524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0         0.764386       0.001339       0.751829      0.002812\n",
       "1         0.773539       0.000469       0.758724      0.003432\n",
       "2         0.778306       0.001038       0.761771      0.003216\n",
       "3         0.782969       0.000663       0.763698      0.003182\n",
       "4         0.786983       0.000523       0.765753      0.003163\n",
       "5         0.790747       0.000881       0.767345      0.002846\n",
       "6         0.794328       0.001146       0.769108      0.003151\n",
       "7         0.798162       0.000776       0.770263      0.003781\n",
       "8         0.802219       0.000628       0.771488      0.003715\n",
       "9         0.806012       0.000749       0.772297      0.003747\n",
       "10        0.809383       0.000608       0.773047      0.003529\n",
       "11        0.812279       0.001135       0.773838      0.003295\n",
       "12        0.815321       0.000727       0.774247      0.003304\n",
       "13        0.817655       0.000798       0.774688      0.003512\n",
       "14        0.820461       0.000703       0.774701      0.003553\n",
       "15        0.822673       0.000602       0.774599      0.003333\n",
       "16        0.825006       0.001082       0.774804      0.003524"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate cross validation\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=NUM_BOOST_ROUNDS,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'auc'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "326178ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=3, min_child_weight=1\n",
      "\tAUC 0.7817244 for 68 rounds\n",
      "\n",
      "CV with max_depth=3, min_child_weight=2\n",
      "\tAUC 0.78139 for 64 rounds\n",
      "\n",
      "CV with max_depth=3, min_child_weight=3\n",
      "\tAUC 0.7814186 for 58 rounds\n",
      "\n",
      "CV with max_depth=3, min_child_weight=4\n",
      "\tAUC 0.7815192000000001 for 52 rounds\n",
      "\n",
      "CV with max_depth=3, min_child_weight=5\n",
      "\tAUC 0.782334 for 60 rounds\n",
      "\n",
      "CV with max_depth=4, min_child_weight=1\n",
      "\tAUC 0.7798044 for 26 rounds\n",
      "\n",
      "CV with max_depth=4, min_child_weight=2\n",
      "\tAUC 0.7802827999999999 for 36 rounds\n",
      "\n",
      "CV with max_depth=4, min_child_weight=3\n",
      "\tAUC 0.7804448 for 30 rounds\n",
      "\n",
      "CV with max_depth=4, min_child_weight=4\n",
      "\tAUC 0.7803692 for 37 rounds\n",
      "\n",
      "CV with max_depth=4, min_child_weight=5\n",
      "\tAUC 0.7813053999999999 for 37 rounds\n",
      "\n",
      "CV with max_depth=5, min_child_weight=1\n",
      "\tAUC 0.7788413999999999 for 23 rounds\n",
      "\n",
      "CV with max_depth=5, min_child_weight=2\n",
      "\tAUC 0.7785797999999999 for 27 rounds\n",
      "\n",
      "CV with max_depth=5, min_child_weight=3\n",
      "\tAUC 0.7785646 for 22 rounds\n",
      "\n",
      "CV with max_depth=5, min_child_weight=4\n",
      "\tAUC 0.7786454 for 20 rounds\n",
      "\n",
      "CV with max_depth=5, min_child_weight=5\n",
      "\tAUC 0.7789086 for 33 rounds\n",
      "\n",
      "CV with max_depth=6, min_child_weight=1\n",
      "\tAUC 0.7766601999999999 for 16 rounds\n",
      "\n",
      "CV with max_depth=6, min_child_weight=2\n",
      "\tAUC 0.7761138000000001 for 18 rounds\n",
      "\n",
      "CV with max_depth=6, min_child_weight=3\n",
      "\tAUC 0.7766232000000001 for 23 rounds\n",
      "\n",
      "CV with max_depth=6, min_child_weight=4\n",
      "\tAUC 0.77668 for 22 rounds\n",
      "\n",
      "CV with max_depth=6, min_child_weight=5\n",
      "\tAUC 0.7776392 for 19 rounds\n",
      "\n",
      "CV with max_depth=7, min_child_weight=1\n",
      "\tAUC 0.7739757999999999 for 13 rounds\n",
      "\n",
      "CV with max_depth=7, min_child_weight=2\n",
      "\tAUC 0.7738394 for 12 rounds\n",
      "\n",
      "CV with max_depth=7, min_child_weight=3\n",
      "\tAUC 0.7736651999999999 for 15 rounds\n",
      "\n",
      "CV with max_depth=7, min_child_weight=4\n",
      "\tAUC 0.7749286 for 19 rounds\n",
      "\n",
      "CV with max_depth=7, min_child_weight=5\n",
      "\tAUC 0.7745932 for 18 rounds\n",
      "\n",
      "Best params: 7, 3, MAE: 0.7736651999999999\n"
     ]
    }
   ],
   "source": [
    "# FINDING THE BEST VALUES FOR MAX_DEPTH AND MIN_CHILD WEIGHT\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,8)\n",
    "    for min_child_weight in range(1,6)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "max_auc = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=NUM_BOOST_ROUNDS,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'auc'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_auc = cv_results['test-auc-mean'].max()\n",
    "    boost_rounds = cv_results['test-auc-mean'].idxmax()\n",
    "    print(\"\\tAUC {} for {} rounds\\n\".format(mean_auc, boost_rounds))\n",
    "    if mean_auc <max_auc:\n",
    "        max_auc=mean_auc\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], max_auc))\n",
    "#print(best_params[0], best_params[1], max_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "424e3d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_child_weight': 3,\n",
       " 'eta': 0.3,\n",
       " 'subsample': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'eval_metric': 'auc'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['max_depth'] = 7\n",
    "params['min_child_weight'] = 3\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e8c3474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "[21:59:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:59:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:59:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:59:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:59:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7736651999999999 for 15 rounds\n",
      "\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "[22:00:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7748846 for 17 rounds\n",
      "\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "[22:00:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:00:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7749765999999999 for 16 rounds\n",
      "\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "[22:01:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7734238 for 16 rounds\n",
      "\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "[22:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:01:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7732378 for 16 rounds\n",
      "\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "[22:02:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7722610000000001 for 11 rounds\n",
      "\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "[22:02:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7733634 for 18 rounds\n",
      "\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "[22:03:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7745962 for 15 rounds\n",
      "\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "[22:03:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.772489 for 13 rounds\n",
      "\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "[22:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7722115999999999 for 15 rounds\n",
      "\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "[22:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7723372000000001 for 16 rounds\n",
      "\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "[22:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7726044 for 11 rounds\n",
      "\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "[22:05:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:05:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:05:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:05:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:05:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7708406 for 12 rounds\n",
      "\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "[22:06:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:06:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:06:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:06:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:06:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7708228 for 12 rounds\n",
      "\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "[22:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:07:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:07:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:07:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:07:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7711222 for 11 rounds\n",
      "\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "[22:07:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:07:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:07:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:07:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:07:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7717061999999999 for 17 rounds\n",
      "\n",
      "Best params: 0.7, 0.9, MAE: 0.7708228\n"
     ]
    }
   ],
   "source": [
    "# FINDING THE BEST VALUES FOR SUBSAMPLE AND COLSAMPLE\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "# Define initial best params and MAE\n",
    "max_auc = float(\"Inf\")\n",
    "best_params = None\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # Update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=NUM_BOOST_ROUNDS,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'auc'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_auc = cv_results['test-auc-mean'].max()\n",
    "    boost_rounds = cv_results['test-auc-mean'].idxmax()\n",
    "    print(\"\\tAUC {} for {} rounds\\n\".format(mean_auc, boost_rounds))\n",
    "    if mean_auc <max_auc:\n",
    "        max_auc=mean_auc\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], max_auc))\n",
    "#print(best_params[0], best_params[1], max_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e23e3264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "[22:38:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7708228 for 12 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "[22:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.774334 for 31 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "[22:39:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:39:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:39:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:39:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:39:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7796512 for 70 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "[22:41:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:41:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:41:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:41:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:41:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAUC 0.7828434 for 165 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "[22:45:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:45:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:45:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:45:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:45:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "\tAUC 0.7845396 for 805 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "[23:05:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:05:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:05:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:05:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:05:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-cdc37764da37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eta'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Run and time CV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     cv_results = xgb.cv(\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mshould_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, obj)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;34m'''Iterate through folds for update'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FINDING BEST VALUES FOR LEARNING RATE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    cv_results = xgb.cv(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=NUM_BOOST_ROUNDS,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['auc'],\n",
    "            early_stopping_rounds=10\n",
    "          )\n",
    "    # Update best score\n",
    "    mean_auc = cv_results['test-auc-mean'].max()\n",
    "    boost_rounds = cv_results['test-auc-mean'].idxmax()\n",
    "    print(\"\\tAUC {} for {} rounds\\n\".format(mean_auc, boost_rounds))\n",
    "    if mean_auc <max_auc:\n",
    "        max_auc=mean_auc\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, AUC: {}\".format(best_params, max_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca914e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_child_weight': 3,\n",
       " 'eta': 0.05,\n",
       " 'subsample': 0.7,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'objective': 'binary:logistic',\n",
       " 'eval_metric': 'auc'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['subsample'] = 0.7\n",
    "params['colsample_bytree'] = 0.9\n",
    "params['eta']=0.05\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "08b35d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:11:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tTest-auc:0.74523\n",
      "[1]\tTest-auc:0.75645\n",
      "[2]\tTest-auc:0.76115\n",
      "[3]\tTest-auc:0.76413\n",
      "[4]\tTest-auc:0.76437\n",
      "[5]\tTest-auc:0.76485\n",
      "[6]\tTest-auc:0.76512\n",
      "[7]\tTest-auc:0.76552\n",
      "[8]\tTest-auc:0.76626\n",
      "[9]\tTest-auc:0.76647\n",
      "[10]\tTest-auc:0.76690\n",
      "[11]\tTest-auc:0.76683\n",
      "[12]\tTest-auc:0.76745\n",
      "[13]\tTest-auc:0.76819\n",
      "[14]\tTest-auc:0.76815\n",
      "[15]\tTest-auc:0.76816\n",
      "[16]\tTest-auc:0.76811\n",
      "[17]\tTest-auc:0.76824\n",
      "[18]\tTest-auc:0.76820\n",
      "[19]\tTest-auc:0.76851\n",
      "[20]\tTest-auc:0.76861\n",
      "[21]\tTest-auc:0.76876\n",
      "[22]\tTest-auc:0.76876\n",
      "[23]\tTest-auc:0.76877\n",
      "[24]\tTest-auc:0.76935\n",
      "[25]\tTest-auc:0.76942\n",
      "[26]\tTest-auc:0.77001\n",
      "[27]\tTest-auc:0.77031\n",
      "[28]\tTest-auc:0.77085\n",
      "[29]\tTest-auc:0.77112\n",
      "[30]\tTest-auc:0.77096\n",
      "[31]\tTest-auc:0.77102\n",
      "[32]\tTest-auc:0.77118\n",
      "[33]\tTest-auc:0.77122\n",
      "[34]\tTest-auc:0.77141\n",
      "[35]\tTest-auc:0.77136\n",
      "[36]\tTest-auc:0.77167\n",
      "[37]\tTest-auc:0.77191\n",
      "[38]\tTest-auc:0.77191\n",
      "[39]\tTest-auc:0.77192\n",
      "[40]\tTest-auc:0.77189\n",
      "[41]\tTest-auc:0.77215\n",
      "[42]\tTest-auc:0.77220\n",
      "[43]\tTest-auc:0.77267\n",
      "[44]\tTest-auc:0.77284\n",
      "[45]\tTest-auc:0.77323\n",
      "[46]\tTest-auc:0.77317\n",
      "[47]\tTest-auc:0.77336\n",
      "[48]\tTest-auc:0.77348\n",
      "[49]\tTest-auc:0.77366\n",
      "[50]\tTest-auc:0.77393\n",
      "[51]\tTest-auc:0.77396\n",
      "[52]\tTest-auc:0.77416\n",
      "[53]\tTest-auc:0.77420\n",
      "[54]\tTest-auc:0.77425\n",
      "[55]\tTest-auc:0.77443\n",
      "[56]\tTest-auc:0.77456\n",
      "[57]\tTest-auc:0.77467\n",
      "[58]\tTest-auc:0.77472\n",
      "[59]\tTest-auc:0.77479\n",
      "[60]\tTest-auc:0.77496\n",
      "[61]\tTest-auc:0.77514\n",
      "[62]\tTest-auc:0.77538\n",
      "[63]\tTest-auc:0.77565\n",
      "[64]\tTest-auc:0.77563\n",
      "[65]\tTest-auc:0.77576\n",
      "[66]\tTest-auc:0.77588\n",
      "[67]\tTest-auc:0.77616\n",
      "[68]\tTest-auc:0.77623\n",
      "[69]\tTest-auc:0.77628\n",
      "[70]\tTest-auc:0.77636\n",
      "[71]\tTest-auc:0.77620\n",
      "[72]\tTest-auc:0.77621\n",
      "[73]\tTest-auc:0.77621\n",
      "[74]\tTest-auc:0.77624\n",
      "[75]\tTest-auc:0.77613\n",
      "[76]\tTest-auc:0.77622\n",
      "[77]\tTest-auc:0.77625\n",
      "[78]\tTest-auc:0.77635\n",
      "[79]\tTest-auc:0.77638\n",
      "[80]\tTest-auc:0.77635\n",
      "[81]\tTest-auc:0.77639\n",
      "[82]\tTest-auc:0.77648\n",
      "[83]\tTest-auc:0.77658\n",
      "[84]\tTest-auc:0.77661\n",
      "[85]\tTest-auc:0.77673\n",
      "[86]\tTest-auc:0.77685\n",
      "[87]\tTest-auc:0.77690\n",
      "[88]\tTest-auc:0.77697\n",
      "[89]\tTest-auc:0.77703\n",
      "[90]\tTest-auc:0.77701\n",
      "[91]\tTest-auc:0.77710\n",
      "[92]\tTest-auc:0.77708\n",
      "[93]\tTest-auc:0.77711\n",
      "[94]\tTest-auc:0.77711\n",
      "[95]\tTest-auc:0.77710\n",
      "[96]\tTest-auc:0.77706\n",
      "[97]\tTest-auc:0.77707\n",
      "[98]\tTest-auc:0.77702\n",
      "[99]\tTest-auc:0.77712\n",
      "[100]\tTest-auc:0.77724\n",
      "[101]\tTest-auc:0.77734\n",
      "[102]\tTest-auc:0.77736\n",
      "[103]\tTest-auc:0.77751\n",
      "[104]\tTest-auc:0.77760\n",
      "[105]\tTest-auc:0.77762\n",
      "[106]\tTest-auc:0.77765\n",
      "[107]\tTest-auc:0.77780\n",
      "[108]\tTest-auc:0.77784\n",
      "[109]\tTest-auc:0.77791\n",
      "[110]\tTest-auc:0.77787\n",
      "[111]\tTest-auc:0.77787\n",
      "[112]\tTest-auc:0.77771\n",
      "[113]\tTest-auc:0.77783\n",
      "[114]\tTest-auc:0.77792\n",
      "[115]\tTest-auc:0.77798\n",
      "[116]\tTest-auc:0.77799\n",
      "[117]\tTest-auc:0.77794\n",
      "[118]\tTest-auc:0.77795\n",
      "[119]\tTest-auc:0.77794\n",
      "[120]\tTest-auc:0.77804\n",
      "[121]\tTest-auc:0.77798\n",
      "[122]\tTest-auc:0.77802\n",
      "[123]\tTest-auc:0.77809\n",
      "[124]\tTest-auc:0.77815\n",
      "[125]\tTest-auc:0.77811\n",
      "[126]\tTest-auc:0.77809\n",
      "[127]\tTest-auc:0.77811\n",
      "[128]\tTest-auc:0.77818\n",
      "[129]\tTest-auc:0.77808\n",
      "[130]\tTest-auc:0.77807\n",
      "[131]\tTest-auc:0.77806\n",
      "[132]\tTest-auc:0.77806\n",
      "[133]\tTest-auc:0.77805\n",
      "[134]\tTest-auc:0.77805\n",
      "[135]\tTest-auc:0.77809\n",
      "[136]\tTest-auc:0.77817\n",
      "[137]\tTest-auc:0.77815\n",
      "[138]\tTest-auc:0.77806\n",
      "Best AUC: 0.78, found at round 128\n"
     ]
    }
   ],
   "source": [
    "# FINDING OPTIMAL NUMBER OF BOOSTING ROUNDS\n",
    "xbg_model1 = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=NUM_BOOST_ROUNDS,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "print(\"Best AUC: {:.2f}, found at round {}\".format(\n",
    "                 xbg_model1.best_score,\n",
    "                 xbg_model1.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b06691e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE XGBOOST MODEL WITH BEST HYPERPARAMETERS\n",
    "xbg_model3 = xgb.train(\n",
    "    params,\n",
    "    drealtrain,\n",
    "    num_boost_round=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ebe7673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3890527 , 0.27708012, 0.41502   , ..., 0.1605968 , 0.63478816,\n",
       "       0.10886513], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICTING\n",
    "y_newpred=xbg_model3.predict(drealtest)\n",
    "p=y_newpred\n",
    "#p=y_newpred[:,1]\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "961fa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMITTING IT TO KAGGLE\n",
    "output2 = pd.DataFrame({'id':ID_test,'target':p})\n",
    "output2.to_csv('netflixxgb5.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
